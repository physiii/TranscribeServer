version: '3.8'

services:
  transcribe:
    restart: always
    build: .
    ports:
      - "8123:8123"
    volumes:
      # Optional: Mount current directory for live code changes (dev only)
      # - .:/app
      # Mount a directory for model cache to persist between runs
      - model_cache:/root/.cache/huggingface/hub
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: [gpu]
    environment:
      # Ensure faster-whisper uses GPU if available
      - NVIDIA_VISIBLE_DEVICES=1
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - TRANSCRIBE_WORKERS=4
      - TRANSCRIBE_PORT=8123
    command: >
      uvicorn main:app
      --host 0.0.0.0
      --port ${TRANSCRIBE_PORT:-8123}
      --workers ${TRANSCRIBE_WORKERS:-4}
      --loop uvloop
      --http httptools

volumes:
  model_cache: 
